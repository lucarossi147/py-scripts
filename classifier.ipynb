{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import os\n",
    "import csv\n",
    "import struct\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from typing import List, Tuple\n",
    "from numpy.core import ndarray\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_name_to_numeric(cn: str) -> int:\n",
    "    if cn == \"SARS-CoV\":\n",
    "        return 0\n",
    "    elif cn == \"SARS-CoV-2\":\n",
    "        return 1\n",
    "    elif cn == \"MERS-CoV\":\n",
    "        return 2\n",
    "    elif cn == \"HCoV-229E\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def class_name_to_numeric_p_n(cn: str) -> int:\n",
    "    if cn == \"Positive\":\n",
    "        return 0\n",
    "    elif cn == \"Negative\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def numeric_to_class_name(cn: int) -> str:\n",
    "    if cn == 0:\n",
    "        return \"SARS-CoV\"\n",
    "    elif cn == 1:\n",
    "        return \"SARS-CoV-2\"\n",
    "    elif cn == 2:\n",
    "        return \"MERS-CoV\"\n",
    "    elif cn == 3:\n",
    "        return \"HCoV-229E\"\n",
    "    else:\n",
    "        return \"Boh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Event:\n",
    "    \"\"\"Feature of single event\"\"\"\n",
    "    class_name: str\n",
    "    amplitude: float \n",
    "    d50: float \n",
    "    normalized_event: ndarray\n",
    "\n",
    "def event_as_list_no_class_name(e: Event):\n",
    "    return [-e.amplitude*1e9, e.d50/100] + list(e.normalized_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_folder = os.path.join(\"C:\\\\\", \"Users\", \"Luca Rossi\", \"Desktop\")\n",
    "results_folder = os.path.join(desktop_folder, \"RESULTS\")\n",
    "proviaml_folder = os.path.join(desktop_folder, \"TRAINING\")\n",
    "virus_folders = [\"SARS-CoV\", \"SARS-CoV-2\", \"MERS-CoV\", \"HCoV-229E\"]\n",
    "positive_negative_folders =[\"Positive\", \"Negative\"]\n",
    "\n",
    "def open_dat(filename):\n",
    "    f = open(filename, \"rb\")\n",
    "    f_cont = f.read()\n",
    "    f.close()\n",
    "    raw = struct.unpack(\"d\" * (len(f_cont) // 8), f_cont)\n",
    "    return np.array(raw)\n",
    "\n",
    "def extract_lengths(filename):\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        events_lengths = []\n",
    "        for row in csv_reader:\n",
    "            if len(row) > 1:\n",
    "                if line_count > 1 and len(row) == 2:\n",
    "                    events_lengths.append(int(row[1]) - int(row[0]))\n",
    "            line_count+=1\n",
    "        return events_lengths\n",
    "\n",
    "def extract_raw_events(dir_name) -> List[ndarray]:\n",
    "    events = []\n",
    "    files = os.listdir(dir_name)\n",
    "    if len(files) == 0:\n",
    "        print(dir_name)\n",
    "        return\n",
    "    dat_file = [os.path.join(dir_name, f) for f in files if f.endswith(\".dat\")].pop()\n",
    "    details_file = [os.path.join(dir_name, f) for f in files if f.endswith(\".csv\")].pop()\n",
    "    # caricamento eventi dal singolo file    \n",
    "    loaded_events = open_dat(dat_file)\n",
    "    # caricamento dettagli file\n",
    "    events_length = extract_lengths(details_file)  \n",
    "    b = 0\n",
    "    for ev_len in events_length:\n",
    "        e = b + ev_len\n",
    "        event = np.array(loaded_events[b:e])\n",
    "        b = e\n",
    "        events.append(event)\n",
    "    return events\n",
    "\n",
    "def duration_x(event: ndarray, baseline, amplitude, percentage):\n",
    "    event_x = np.nonzero(event < baseline - amplitude * percentage )[0]\n",
    "    # istante in cui l'evento supera la percentuale x dell'escursione\n",
    "    begin_x = event_x[0]\n",
    "    # istante in cui l'evento torna al di sotto della percentuale x dell'escursione\n",
    "    end_x = event_x[-1]\n",
    "    return end_x - begin_x\n",
    "\n",
    "def calc_baseline(event: ndarray) -> float:\n",
    "    ev_len = event.size\n",
    "    x_baseline = np.concatenate((event[:round(ev_len/5*0.2)], event[round(ev_len - ev_len/5*0.2):]))\n",
    "    return np.mean(x_baseline)\n",
    "\n",
    "def normalize_waveform(event:ndarray, stereotype_length = 35) -> ndarray:\n",
    "    ev_len = event.size\n",
    "    amplitude = event.max()\n",
    "    x = np.array([x for x in range(ev_len)])\n",
    "    x_norm = np.linspace(0, ev_len-1, stereotype_length*3+4)\n",
    "    f = interp1d(x, event/amplitude, kind='cubic')\n",
    "    event_norm = f(x_norm)\n",
    "    event_norm = event_norm[stereotype_length+2:2*stereotype_length+2]\n",
    "    return event_norm\n",
    "\n",
    "def extract_events(raw_events: List[ndarray], class_name) -> Tuple[str, List[Event]]:\n",
    "    events = []\n",
    "    if raw_events is None:\n",
    "        return events\n",
    "    for event in raw_events:\n",
    "        peak = event.max()\n",
    "        baseline = calc_baseline(event)\n",
    "        amplitude = baseline - peak\n",
    "        d50 = duration_x(event, baseline, amplitude, 0.5)\n",
    "        normalized_event = normalize_waveform(event)\n",
    "        if np.count_nonzero(normalized_event < - 0.1) or np.count_nonzero(normalized_event > 1):\n",
    "            continue\n",
    "        events.append(Event(class_name, amplitude, d50, normalized_event))\n",
    "    return events\n",
    "\n",
    "def get_classes_and_paths(results_folder: List[str], virus_folders:List[str]):\n",
    "    class_and_path_to_virus_dir = [ (v, os.path.join(results_folder, v)) for v in virus_folders]\n",
    "    classes_and_paths = []\n",
    "    for v, p in class_and_path_to_virus_dir:\n",
    "        for new_p in [os.path.join(p, d) for d in os.listdir(p)]:\n",
    "            classes_and_paths.append((v, new_p))            \n",
    "    return classes_and_paths\n",
    "\n",
    "def shuffle(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    l = len(a)\n",
    "    p = np.random.permutation(l)\n",
    "    p = p.astype(int)\n",
    "    return [a[i] for i in p], [b[i] for i in p]\n",
    "\n",
    "\n",
    "def resample(events):\n",
    "    classes = [class_name_to_numeric_p_n(e.class_name) for e in events]\n",
    "    pos_classes = [c for c in classes if c == 0]\n",
    "    neg_classes = [c for c in classes if c == 1]\n",
    "    pos_events = [e for e in events if e.class_name == \"Positive\"]\n",
    "    neg_events = [e for e in events if e.class_name == \"Negative\"]\n",
    "    if len(pos_events) > len(neg_events):\n",
    "        pos_events_shuffled, pos_classes_shuffled = shuffle(pos_events, pos_classes)\n",
    "        events = pos_events_shuffled[:len(neg_events)] + neg_events\n",
    "        classes = pos_classes_shuffled[:len(neg_events)] + neg_classes\n",
    "    else:\n",
    "        neg_events_shuffled,neg_classes_shuffled = shuffle(neg_events, neg_classes)\n",
    "        events = pos_events + neg_events_shuffled[:len(pos_events)]\n",
    "        classes = pos_classes + neg_classes_shuffled[:len(pos_classes)]\n",
    "    return shuffle(events, classes)\n",
    "\n",
    "def predict_entire_file(clf, events: List[Event]):\n",
    "    results = {\"SARS-CoV\": 0, \"SARS-CoV-2\": 0, \"MERS-CoV\": 0, \"HCoV-229E\": 0}\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    predictions = clf.predict(features)\n",
    "    results[\"SARS-CoV\"] = len([p for p in predictions if p == 0])\n",
    "    results[\"SARS-CoV-2\"] = len([p for p in predictions if p == 1])\n",
    "    results[\"MERS-CoV\"] = len([p for p in predictions if p == 2])\n",
    "    results[\"HCoV-229E\"] = len([p for p in predictions if p == 3])\n",
    "    print(results)\n",
    "    return max(results, key=results.get)\n",
    "\n",
    "def predict_entire_file_p_n(clf, events: List[Event]):\n",
    "    results = {\"Positive\": 0, \"Negative\": 0}\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    predictions = clf.predict(features)\n",
    "    results[\"Positive\"] = len([p for p in predictions if p == 0])\n",
    "    results[\"Negative\"] = len([p for p in predictions if p == 1])\n",
    "    print(results)\n",
    "    return max(results, key=results.get)\n",
    "\n",
    "def get_predictions_of_entire_file_p_n(clf, events: List[Event]):\n",
    "    results = {\"Positive\": 0, \"Negative\": 0}\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    predictions = clf.predict(features)\n",
    "    results[\"Positive\"] = len([p for p in predictions if p == 0])\n",
    "    results[\"Negative\"] = len([p for p in predictions if p == 1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p = get_classes_and_paths(results_folder, virus_folders)\n",
    "c_p_re = [ (c, p, extract_raw_events(p)) for c, p in c_p]\n",
    "c_p_e = [(c, p, extract_events(re, c)) for c, p, re in c_p_re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_for_analysis = [item for sublist in [e for _, _, e in c_p_e] for item in sublist]\n",
    "classes_for_analysis = [e.class_name for e in events_for_analysis]\n",
    "for v in virus_folders:\n",
    "    print(v, len([c for c in classes_for_analysis if c == v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "dummy_confusion_matrix = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "dummy = DummyClassifier()\n",
    "# clf = RandomForestClassifier(class_weight=\"balanced_subsample\")\n",
    "clf = MLPClassifier(hidden_layer_sizes=(20,), activation='tanh',learning_rate_init=0.3, max_iter=500, random_state=0,\n",
    " momentum=0.2, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, batch_size = 100)\n",
    "for idx in range(len(c_p_e)):\n",
    "    test = c_p_e[idx]\n",
    "    train = [c_p_e[i] for i in range(len(c_p_e)) if i != idx]\n",
    "    events = [item for sublist in [e for _, _, e in train] for item in sublist]\n",
    "    classes = [class_name_to_numeric(e.class_name) for e in events]\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    clf.fit(features, classes)\n",
    "    dummy.fit(features, classes)\n",
    "    test_class, _, test_events = test\n",
    "    print(test_class)\n",
    "    prediction = predict_entire_file(clf, test_events)\n",
    "    dummy_pred = predict_entire_file(dummy, test_events)\n",
    "    confusion_matrix[class_name_to_numeric(test_class)][class_name_to_numeric(prediction)] += 1\n",
    "    dummy_confusion_matrix[class_name_to_numeric(test_class)][class_name_to_numeric(dummy_pred)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(confusion_matrix))\n",
    "print(np.array(dummy_confusion_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\AS-2-2-bias+01_BK-1126_045fil_TI\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\AS-2-2-bias+01_BK-953_045fil_TI_1st\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\F2\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\F8 day1\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-112720-46\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-112720-58\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-17\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-32\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-33\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-44\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120720-46\n",
      "C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120720-6\n"
     ]
    }
   ],
   "source": [
    "c_p_saliva = get_classes_and_paths(proviaml_folder, positive_negative_folders)\n",
    "c_p_re_saliva = [ (c, p, extract_raw_events(p)) for c, p in c_p_saliva]\n",
    "c_p_e_saliva = [(c, p, extract_events(re, c)) for c, p, re in c_p_re_saliva]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_n_confusion_matrix = [[0,0],[0,0]]\n",
    "p_n_dummy_confusion_matrix = [[0,0],[0,0]]\n",
    "# dummy = DummyClassifier()\n",
    "clf = RandomForestClassifier(class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(20,), activation='tanh',learning_rate_init=0.3, max_iter=500, random_state=0,\n",
    "#  momentum=0.2, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, batch_size = 100)\n",
    "for idx in range(len(c_p_e_saliva)):\n",
    "    test_class, test_path, test_events = c_p_e_saliva[idx]\n",
    "    if len(test_events) == 0:\n",
    "        print(\"no test events for \", test_path)\n",
    "        continue\n",
    "    train = [c_p_e_saliva[i] for i in range(len(c_p_e_saliva)) if i != idx]\n",
    "    events = [item for sublist in [e for _, _, e in train] for item in sublist]\n",
    "    events, classes = resample(events)\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    print(test_class)\n",
    "    clf.fit(features, classes)\n",
    "    # dummy.fit(features, classes)\n",
    "    prediction = predict_entire_file_p_n(clf, test_events)\n",
    "    # dummy_pred = predict_entire_file_p_n(dummy, test_events)\n",
    "    p_n_confusion_matrix[class_name_to_numeric_p_n(test_class)][class_name_to_numeric_p_n(prediction)] += 1\n",
    "    # p_n_dummy_confusion_matrix[class_name_to_numeric_p_n(test_class)][class_name_to_numeric_p_n(dummy_pred)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(p_n_confusion_matrix))\n",
    "print(np.array(p_n_dummy_confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificatore basato su file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureOfFile:\n",
    "    \"\"\"Feature of File\"\"\"\n",
    "    class_name: str\n",
    "    n_events: int\n",
    "    n_events_classified_as_positive: int\n",
    "    n_events_classified_as_negative: int\n",
    "    hist_of_amplitudes: ndarray\n",
    "    hist_of_d50s: ndarray\n",
    "\n",
    "def feature_file_as_list_no_class_name(f: FeatureOfFile):\n",
    "    return [f.n_events, f.n_events_classified_as_positive, f.n_events_classified_as_negative] + list(f.hist_of_amplitudes) + list(f.hist_of_d50s)\n",
    "\n",
    "def feature_of_file_from_events(class_name: str, evs: List[Event], clf ) -> FeatureOfFile:\n",
    "    n_events = len(evs)\n",
    "    amplitudes = [e.amplitude for e in evs]\n",
    "    d50s =  [e.d50 for e in evs]\n",
    "    hist_of_amplitudes, _ = np.histogram(amplitudes)\n",
    "    hist_of_d50s, _ = np.histogram(d50s)\n",
    "    dict_of_predictions = get_predictions_of_entire_file_p_n(clf, evs)\n",
    "    n_events_classified_as_positive, n_events_classified_as_negative = dict_of_predictions[\"Positive\"], dict_of_predictions[\"Negative\"]\n",
    "    return FeatureOfFile(class_name, n_events=n_events, n_events_classified_as_positive=n_events_classified_as_positive, \n",
    "    n_events_classified_as_negative=n_events_classified_as_negative, hist_of_amplitudes=hist_of_amplitudes, hist_of_d50s=hist_of_d50s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\AS-2-2-bias+01_BK-1126_045fil_TI\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\AS-2-2-bias+01_BK-953_045fil_TI_1st\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\F2\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "Positive\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Positive\\F8 day1\n",
      "Positive\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-112720-46\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-112720-58\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-17\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-32\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-33\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120420-44\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120720-46\n",
      "Negative\n",
      "no test events for  C:\\Users\\Luca Rossi\\Desktop\\TRAINING\\Negative\\HD-120720-6\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "p_n_confusion_matrix_file = [[0,0],[0,0]]\n",
    "clf1 = RandomForestClassifier(class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "clf2 = RandomForestClassifier(class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "for idx in range(len(c_p_e_saliva)):\n",
    "    test_class, test_path, test_events = c_p_e_saliva[idx]\n",
    "    if len(test_events) == 0:\n",
    "        print(\"no test events for \", test_path)\n",
    "        continue\n",
    "    train = [c_p_e_saliva[i] for i in range(len(c_p_e_saliva)) if i != idx]\n",
    "    events = [item for sublist in [e for _, _, e in train] for item in sublist] \n",
    "    events, classes = resample(events)\n",
    "    features = [event_as_list_no_class_name(e) for e in events]\n",
    "    clf1.fit(features, classes)\n",
    "    # fare ribilanciamento anche di qua?\n",
    "    train =  [(c, p, e) for c, p, e in train if len(e) > 0]\n",
    "    features_of_files = [feature_of_file_from_events(c, e, clf1) for c, _, e in train]\n",
    "    classes = [class_name_to_numeric_p_n(f.class_name) for f in features_of_files]\n",
    "    features = [feature_file_as_list_no_class_name(f) for f in features_of_files]\n",
    "    features, classes = shuffle(features, classes)\n",
    "    clf2.fit(features, classes)\n",
    "\n",
    "    test_feature = feature_of_file_from_events(test_class, test_events, clf1)\n",
    "    print(test_feature.class_name)\n",
    "    # Faccio prediction su un solo elemento\n",
    "    prediction = clf2.predict([feature_file_as_list_no_class_name(test_feature)])\n",
    "    p_n_confusion_matrix_file[class_name_to_numeric_p_n(test_class)][prediction[0]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  3],\n",
       "       [27,  5]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(p_n_confusion_matrix_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4825308895f39589ea0bf8845fde4277dc8e6c0cfe1c78f3b6a42f274c89776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
