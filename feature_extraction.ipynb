{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e61946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import struct\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.interpolate import interp1d, CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from numpy.core import ndarray\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449207da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureSingleEvent:\n",
    "    \"\"\"Feature of single event\"\"\"\n",
    "    class_name: str\n",
    "    peak: float \n",
    "    baseline: float \n",
    "    amplitude: float \n",
    "    d50: float \n",
    "    normalized_event: ndarray\n",
    "\n",
    "def feature_single_event_as_list(f: FeatureSingleEvent):\n",
    "    return [f.peak, f.baseline, f.amplitude, f.d50] + list(f.normalized_event) + [f.class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a412b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Feature:    \n",
    "    \"\"\"Feature of a measurement\"\"\"\n",
    "    class_name: str\n",
    "    avg_peak:float \n",
    "    max_peak:float\n",
    "    avg_baseline:float\n",
    "    avg_amplitudes:float \n",
    "    avg_d50:float\n",
    "    stereotype: ndarray\n",
    "    \n",
    "def feature_as_list(f: Feature):\n",
    "    return [f.avg_peak, f.max_peak, f.avg_baseline, f.avg_amplitudes, f.avg_d50, f.stereotype.size] + list(f.stereotype) + [f.class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13049de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureWithoutStereotype:    \n",
    "    \"\"\"Feature of a measurement\"\"\"\n",
    "    class_name: str\n",
    "    avg_peak:float \n",
    "    max_peak:float\n",
    "    avg_baseline:float\n",
    "    avg_amplitudes:float \n",
    "    avg_d50:float\n",
    "        \n",
    "def remove_stereotype(f: Feature):\n",
    "    return FeatureWithoutStereotype(f.class_name, f.avg_peak, f.max_peak, f.avg_baseline, f.avg_amplitudes, f.avg_d50)\n",
    "    \n",
    "\n",
    "def feature_without_stereotype_as_list(f: FeatureWithoutStereotype):\n",
    "    return [f.avg_peak, f.max_peak, f.avg_baseline, f.avg_amplitudes, f.avg_d50, f.stereotype.size, f.class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206dd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forma d'onda normalizzata:\n",
    "# in ampiezza dividendo per amplitude\n",
    "# in durata facendo la spline su un numero fisso di campioni\n",
    "def backup_normalize(event:ndarray, stereotype_length = 35) -> ndarray:\n",
    "    ev_len = event.size\n",
    "    normalizing_factor = abs(get_peak(event).min())\n",
    "    x = [x for x in range(ev_len)]\n",
    "    x_norm = np.linspace(0, ev_len-1, stereotype_length*3+4)\n",
    "    f = interp1d(x, event/normalizing_factor)\n",
    "    event_norm = f(x_norm)\n",
    "    return event_norm[stereotype_length+3:2*stereotype_length+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d980611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_plots = True\n",
    "# show_events_plots = True\n",
    "\n",
    "\n",
    "# event_stereotype_file_path = '/home/luca/py-scripts/event_stereotype_stored'\n",
    "# event_stereotype_file_path =  os.path.join(\"C:\\\\\",\"Users\", \"Luca Rossi\", \"Desktop\",\"py-scripts\", \"event_stereotype_stored\")\n",
    "\n",
    "# root_folder = r\"/home/luca/Desktop/SARS-CoV\"\n",
    "# root_folder = os.path.join(\"C:\\\\\",\"Users\", \"Luca Rossi\", \"Desktop\", \"extracted events\")\n",
    "# event_folders = [root_folder + os.sep + d for d in os.listdir(root_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df563fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dat(filename):\n",
    "    f = open(filename, \"rb\")\n",
    "    f_cont = f.read()\n",
    "    f.close()\n",
    "    raw = struct.unpack(\"d\" * (len(f_cont) // 8), f_cont)\n",
    "    return np.array(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d718cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(events: List[ndarray], name = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    if name is not None:\n",
    "        ax.set_title(name)\n",
    "    for e in events:\n",
    "        ax.plot(e)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1ac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_plot(events: List[ndarray], name = None):\n",
    "    for e in events:\n",
    "        fig, ax = plt.subplots()\n",
    "        if name is not None:\n",
    "            ax.set_title(name)\n",
    "        ax.plot(e)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9f016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(features: List[Tuple[float,float,float,float,ndarray]], name = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    if name is not None:\n",
    "        ax.set_title(name)\n",
    "    for f in features:\n",
    "        _, _, _, _, n = f\n",
    "        ax.plot(n)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e720396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_dat(filename):\n",
    "    raw = open_dat(filename)\n",
    "    plt.plot(raw)\n",
    "    plt.show\n",
    "# folder = \"/home/luca/Desktop/SARS-CoV/NK-2-1-SARSx10-2nd_001\"\n",
    "# # view_dat()\n",
    "# evs = extract_events(folder)\n",
    "# plot(evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741ace10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak(event: ndarray) -> ndarray:\n",
    "    return event[event.size//5*2: event.size//5*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e3563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lengths(filename):\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        events_lengths = []\n",
    "        for row in csv_reader:\n",
    "            if len(row) > 1:\n",
    "                if line_count > 1:\n",
    "                    events_lengths.append(int(row[1]) - int(row[0]))\n",
    "            line_count+=1\n",
    "        return events_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e5f4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(dir_name) -> List[ndarray]:\n",
    "    files = os.listdir(dir_name)\n",
    "    dat_file = [dir_name + os.sep + f for f in files if f.endswith(\".dat\")].pop()\n",
    "    details_file = [dir_name + os.sep + f for f in files if f.endswith(\".csv\")].pop()\n",
    "    # caricamento eventi dal singolo file    \n",
    "    loaded_events = open_dat(dat_file)\n",
    "    # caricamento dettagli file\n",
    "    events_length = extract_lengths(details_file)\n",
    "    \n",
    "    events = []\n",
    "    b = 0\n",
    "    for ev_len in events_length:\n",
    "        e = b + ev_len\n",
    "        event = np.array(loaded_events[b:e])\n",
    "        b = e\n",
    "        events.append(event)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ce58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_events(events: List[ndarray]) -> List[ndarray]:\n",
    "    return [e for e in events if e.size > 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d683e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noisy_events(events: List[ndarray]) -> List[ndarray]:\n",
    "    return [e for e in events if abs(e.min()) - abs(e.max()) > 0.1 * abs(e.min())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421ada62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# durata dal momento in cui l'evento supera la percentuale x dell'escursione\n",
    "# al momento in cui torna al di sotto della percentuale x dell'escursione\n",
    "def duration_x(event: ndarray, baseline, amplitude, percentage):\n",
    "    event_x = np.nonzero(event < baseline - amplitude * percentage )[0]\n",
    "    # istante in cui l'evento supera la percentuale x dell'escursione\n",
    "    begin_x = event_x[0]\n",
    "    # istante in cui l'evento torna al di sotto della percentuale x dell'escursione\n",
    "    end_x = event_x[-1]\n",
    "    return end_x - begin_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43d28dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo la baseline sul primo 20% del primo quinto dei dati e\n",
    "# sull'ultimo 20% dell'ultimo quinto dei dati\n",
    "def calc_baseline(event: ndarray) -> float:\n",
    "    ev_len = event.size\n",
    "    x_baseline = np.concatenate((event[:round(ev_len/5*0.2)], event[round(ev_len - ev_len/5*0.2):]))\n",
    "    return np.mean(x_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7cd74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forma d'onda normalizzata:\n",
    "# in ampiezza dividendo per amplitude\n",
    "# in durata facendo la spline su un numero fisso di campioni\n",
    "def normalize_waveform(event:ndarray, stereotype_length = 35) -> ndarray:\n",
    "    ev_len = event.size\n",
    "    amplitude = abs(get_peak(event).min())\n",
    "    x = np.array([x for x in range(ev_len)])\n",
    "    x_norm = np.linspace(0, ev_len-1, stereotype_length*3+4)\n",
    "    f = interp1d(x, event/amplitude, kind='cubic')\n",
    "    event_norm = f(x_norm)\n",
    "    return event_norm[stereotype_length+2:2*stereotype_length+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7379123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_single_events(events_to_process: List[ndarray], class_name: str) -> List[FeatureSingleEvent]:\n",
    "    features = []\n",
    "    for event in events_to_process:\n",
    "        peak = get_peak(event).min()\n",
    "        baseline = calc_baseline(event)\n",
    "        amplitude = baseline - peak\n",
    "        d50 = duration_x(event, baseline, amplitude, 0.5)\n",
    "        normalized_event = normalize_waveform(event)\n",
    "        if normalized_event.max() < 0.2 and normalized_event.min() >= -1:\n",
    "            features.append(FeatureSingleEvent(class_name, peak, baseline, amplitude, d50, normalized_event))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad5fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list_of_features(list_of_features: ndarray):\n",
    "    mean = np.mean(list_of_features)\n",
    "    std_dev = np.std(list_of_features)\n",
    "    return np.array([(f-mean) * std_dev for f in list_of_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "803bad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa solo le feature migliori e piu' robuste\n",
    "def refine_features(features_to_process: List[FeatureSingleEvent]) -> Feature:\n",
    "    if features_to_process is None or len(features_to_process) == 0:\n",
    "        return None\n",
    "    peaks = np.array([f.peak for f in features_to_process])\n",
    "    baselines = np.array([f.baseline for f in features_to_process])\n",
    "    amplitudes = np.array([f.amplitude for f in features_to_process])\n",
    "    d50s = np.array([f.d50 for f in features_to_process])\n",
    "    normalized_events = np.array([f.normalized_event for f in features_to_process])\n",
    "    avg_peak = np.mean(peaks)\n",
    "    max_peak = peaks.max()\n",
    "    avg_baseline = np.mean(baselines)\n",
    "    avg_amplitudes = np.mean(amplitudes)\n",
    "    avg_d50 = np.mean(d50s)\n",
    "    stereotype = np.sum(normalized_events, axis=0)/len(normalized_events)\n",
    "    return Feature(features_to_process[0].class_name, avg_peak, max_peak,avg_baseline,avg_amplitudes, avg_d50, stereotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f05f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "349cfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_stuff(dir_name):\n",
    "    print(\"extracting events from \"+dir_name)\n",
    "    events = extract_events(dir_name)\n",
    "    print(\"events are \" + str(len(events)))\n",
    "    print(\"removing short events\")\n",
    "    events = remove_short_events(events)\n",
    "    print(\"events are \" + str(len(events)))\n",
    "    print(\"removing noisy events\")\n",
    "    events = remove_noisy_events(events)\n",
    "    print(\"events are \" + str(len(events)))\n",
    "    print(\"plotting events\")\n",
    "    plot(events, dir_name)\n",
    "    print(\"extracting features\")\n",
    "    print(\"dir name\",dir_name.split(os.sep).pop())\n",
    "    features = extract_features_single_events(events, dir_name.split(os.sep).pop())\n",
    "    print(\"plotting normalized events\")\n",
    "#     plot([f[-1] for f in features])\n",
    "    feature = refine_features(features)\n",
    "    plot([feature.stereotype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee99b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing stuff\n",
    "# first_measurement_dir = event_folders[0]\n",
    "# debug_stuff(first_measurement_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd767c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for measurement in event_folders:\n",
    "#     debug_stuff(measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59923332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_events(dir_name, class_name) -> List[FeatureSingleEvent]:\n",
    "    events = extract_events(dir_name)\n",
    "    events = remove_short_events(events)\n",
    "    events = remove_noisy_events(events)\n",
    "    features = extract_features_single_events(events, class_name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac844667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(dir_name, class_name):\n",
    "    features = extract_features_from_events(dir_name, class_name)\n",
    "    return refine_features(features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe07016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_header(feature_type: str = \"Feature\"):\n",
    "    values = [\"v\"+str(i) for i in range(35)]\n",
    "    if feature_type == \"Feature\":\n",
    "        return [\"avg_peak\", \"max_peak\", \"avg_baseline\", \"avg_amplitudes\", \"avg_d50\", \"number_of_events\"] + values + [\"class\"]\n",
    "    elif feature_type == \"FeatureSingleEvent\":\n",
    "        return [\"peak\", \"baseline\", \"amplitude\", \"d50\"] + values + [\"class\"]\n",
    "    \n",
    "# print(generate_header())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47c4a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(path_to_file: str, header, rows):\n",
    "    path_to_file = path_to_file + \".csv\" if not path_to_file.endswith(\".csv\") else path_to_file\n",
    "    with open(path_to_file, 'w', newline=\"\") as f:\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(f)\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e877d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(root_folder, list_of_folders_to_analyze, func):\n",
    "    infos = []\n",
    "    for fta in list_of_folders_to_analyze:\n",
    "        folder_to_analyze = os.path.join(root_folder, fta)\n",
    "        measurements_folders = [folder_to_analyze + os.sep + d for d in os.listdir(folder_to_analyze)]\n",
    "        for mf in measurements_folders:\n",
    "            res = func(mf, fta)\n",
    "            if res is not None:\n",
    "                #res is a list of feature_single_event, add the list to the one to return\n",
    "                if isinstance(res, list):\n",
    "                    infos += res\n",
    "                # res is a single feature:\n",
    "                else:\n",
    "                    infos.append(res)\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c27fea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_folder = os.path.join(\"/home\", \"luca\", \"Desktop\")\n",
    "#desktop_folder = os.path.join(\"C:\\\\\", \"Users\", \"Luca Rossi\", \"Desktop\")\n",
    "virus_folders = [\"SARS-CoV\", \"SARS-CoV-2\", \"MERS-CoV\", \"HCoV-229E\"]\n",
    "training_folder = os.path.join(desktop_folder, \"training\")\n",
    "test_folder = os.path.join(desktop_folder, \"test\")\n",
    "positive_negative_folders = [\"positive\", \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52e1e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAZIONE CSV DI FEATURE DA EVENTI SINGOLI PER MACHINE LEARNING\n",
    "infos = analyze(desktop_folder, virus_folders, extract_features_from_events)\n",
    "header =  generate_header(\"FeatureSingleEvent\")\n",
    "rows = [feature_single_event_as_list(f) for f in infos]\n",
    "save_to_csv(\"features_from_single_events\",header, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7540d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAZIONE CSV DI FEATURE PER MACHINE LEARNING\n",
    "infos = analyze(desktop_folder, virus_folders, extract)\n",
    "header = generate_header(\"Feature\")\n",
    "rows = [feature_as_list(f) for f in infos]\n",
    "\n",
    "save_to_csv(\"features\",header, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a190deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO REFACTOR THIS SHIT\n",
    "def normalize_features_without_stereotype(features_without_stereotype: List[FeatureWithoutStereotype])->List[FeatureWithoutStereotype]:\n",
    "    class_names = [f.class_name for f in features_without_stereotype]\n",
    "    peaks = normalize_list_of_features(np.array([f.avg_peak for f in features_without_stereotype]))\n",
    "    max_peaks = normalize_list_of_features(np.array([f.max_peak for f in features_without_stereotype]))\n",
    "    baselines = normalize_list_of_features(np.array([f.avg_baseline for f in features_without_stereotype]))\n",
    "    amplitudes = normalize_list_of_features(np.array([f.avg_amplitudes for f in features_without_stereotype]))\n",
    "    d50s = normalize_list_of_features(np.array([f.avg_d50 for f in features_without_stereotype]))\n",
    "    fws_normalized = []\n",
    "    for c, p, mp, b, a, d in zip(class_names, peaks, max_peaks, baselines, amplitudes, d50s):\n",
    "        fws_normalized.append(FeatureWithoutStereotype(c, p, mp, b, a, d))\n",
    "    return fws_normalized\n",
    "\n",
    "#TODO ORA COME ORA NORMALIZZA LE FEATURES E RIMUOVE GLI STEREOTIPI\n",
    "def normalize_features(features: List[Feature]) -> List[FeatureWithoutStereotype]:\n",
    "    return normalize_features_without_stereotype([remove_stereotype(f) for f in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAZIONE CSV TRAINING NORMALIZZATO SENZA STEREOTIPO DI EVENTO\n",
    "infos = analyze(training_folder, positive_negative_folders, extract)\n",
    "#PER NON NORMALIZZARE COMMENTARE LA RIGA SOTTO\n",
    "infos = normalize_features(infos)\n",
    "\n",
    "header = generate_header(\"Feature\")\n",
    "rows = [feature_as_list(f) for f in infos]\n",
    "\n",
    "save_to_csv(\"training_data_normalized\",header, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf65ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAZIONE CSV TEST NORMALIZZATO SENZA STEREOTIPO DI EVENTO\n",
    "infos = analyze(test_folder, positive_negative_folders, extract)\n",
    "#PER NON NORMALIZZARE COMMENTARE LA RIGA SOTTO\n",
    "infos = normalize_features(infos)\n",
    "\n",
    "header = generate_header(\"Feature\")\n",
    "rows = [feature_as_list(f) for f in infos]\n",
    "\n",
    "save_to_csv(\"training_data_normalized\",header, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = infos[0]\n",
    "# print(feature.stereotype.size)\n",
    "print(len(feature_as_list(feature)))\n",
    "save_to_csv(\"features\",header, rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
